Adaptive Image Compression Using Domain-Specific Autoencoders

This project implements an adaptive, domain-aware image compression system using multiple CNN-based autoencoders, each trained on a specific image category.
A classifier automatically selects the correct autoencoder for each input image, resulting in higher reconstruction quality compared to a single generic autoencoder.

The project includes training, evaluation, automatic routing, and visualization for the following four image domains:

Natural Images (STL10)

Satellite Images (EuroSAT)

Cartoon / Synthetic Images (PyTorch FakeData)

Text Images (Custom synthetic dataset)

âœ¨ Features

âœ” Four specialized autoencoders (one per image domain)

âœ” Image-type classifier to choose the best autoencoder

âœ” End-to-end adaptive compression pipeline

âœ” PSNR & SSIM evaluation for reconstruction quality

âœ” Visualization of original vs reconstructed images

âœ” Unified evaluation across all datasets

âœ” Model saving and loading support

ğŸ“‚ Project Structure
â”œâ”€â”€ datasets/                 # All datasets downloaded or generated
â”œâ”€â”€ saved_models/             # Trained AEs and classifier weights
â”œâ”€â”€ main.ipynb / script.py    # Full training + evaluation code
â”œâ”€â”€ README.md                 # Documentation
â””â”€â”€ requirements.txt          # Dependencies

ğŸ§  Methodology
1. Datasets
Domain	Dataset	Purpose
Natural	STL10	Real-world photography
Satellite	EuroSAT	Aerial remote sensing
Cartoon	FakeData	Synthetic cartoon-like images
Text	Custom PIL-rendered text	OCR-style images

The images are resized to 128Ã—128 and normalized to [0, 1].

ğŸ§© Models
1. Domain-Specific Autoencoders

Each domain uses its own autoencoder with:

Convolutional encoder (downsampling Ã—4)

Latent bottleneck (512 channels)

Transposed-convolution decoder (upsampling Ã—4)

Sigmoid activation for 0â€“1 output

Autoencoder names:

Domain	Autoencoder
Cartoon	ae_cartoon
Natural	ae_natural
Satellite	ae_satellite
Text	ae_text
2. Image Type Classifier

The classifier is a CNN-based architecture with:

4 Conv + ReLU + MaxPool layers

Flatten + Linear â†’ 512 â†’ 4 output classes

Softmax for prediction

Classes:

0 = Cartoon
1 = Natural
2 = Satellite
3 = Text

ğŸ”„ Training Workflow
Step 1: Train Autoencoders

Each dataset trains its own autoencoder independently.

AE loss: MSELoss
Optimizer: Adam (lr = 1e-3)
Epochs: 30

Step 2: Train Classifier

Datasets are combined using ConcatDataset.

Classifier loss: CrossEntropyLoss
Optimizer: Adam (lr = 1e-3)
Epochs: 30

Step 3: Adaptive Compression

For every input image:

Classifier predicts domain

Corresponding autoencoder selected

Image encoded â†’ compressed â†’ decoded

Compute reconstruction quality

Display results

ğŸ“Š Evaluation Metrics

The system computes:

PSNR (Peak Signal-to-Noise Ratio)

Measures pixel-level accuracy (higher = better).

SSIM (Structural Similarity Index)

Measures perceptual similarity (higher = better).

Both are widely used in image compression research.

ğŸ–¼ï¸ Visualization

The visualize_results() function displays:

Original image

Reconstructed image

PSNR value

SSIM score

Predicted domain

Compression statistics

Example:

Original | Reconstruction
PSNR: 29.8, SSIM: 0.91, Pred: Natural
Compression: 49152 â†’ 8192

â–¶ï¸ How to Run
1. Install dependencies
pip install -r requirements.txt

2. Run the script
python main.py

3. Trained model files will appear in:
saved_models/

4. View visualizations in the notebook or display windows.
